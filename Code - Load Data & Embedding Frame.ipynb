{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from auxiliar_functions import process_folds, build_report, load_dataset, predict_deep, load_embedding\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import torch \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from AsymmetricLoss import AsymmetricLossOptimized\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import gc\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "spanish_stopwords = nltk.corpus.stopwords.words('spanish') + [\"UNK\"]\n",
    "\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicar Fold a trabajar - Debe ser un número de 1 a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1\n",
    "assert FOLD in range(1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>encoded</th>\n",
       "      <th>frames</th>\n",
       "      <th>conflicto</th>\n",
       "      <th>economico</th>\n",
       "      <th>humanidad</th>\n",
       "      <th>moral</th>\n",
       "      <th>fasttext</th>\n",
       "      <th>elmo</th>\n",
       "      <th>beto_embedding_mean</th>\n",
       "      <th>beto_embedding_cls</th>\n",
       "      <th>Bi-LSTM</th>\n",
       "      <th>Bi-LSTM_AsymetricLoss</th>\n",
       "      <th>Beto-finetunning_cross_entropy</th>\n",
       "      <th>Beto-finetunning_asymetric</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japón registró un nuevo déficit comercial réco...</td>\n",
       "      <td>japón registró un nuevo déficit comercial réco...</td>\n",
       "      <td>[8759, 8914, 9989, 9898, 6584, 8773, 8428, 999...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.10552764, -0.27450845, -0.04605328, -0.244...</td>\n",
       "      <td>[0.0596153, -0.49882528, -0.41697934, 0.367517...</td>\n",
       "      <td>[-0.23091996, -0.10888031, -0.41678736, 0.6554...</td>\n",
       "      <td>[0.36867273, -0.11450332, -0.70039237, 1.38560...</td>\n",
       "      <td>[0.06928335, 0.43591627, 0.09116903, 0.6328583...</td>\n",
       "      <td>[0.00010779064, -0.005758822, 0.15181892, 0.00...</td>\n",
       "      <td>[0.113271594, -0.13349481, -0.17376488, -0.254...</td>\n",
       "      <td>[-0.2676692, 0.06710381, -0.028014764, -0.1380...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UDI acusa \"mala memoria\" de la Nueva Mayoría f...</td>\n",
       "      <td>udi acusa mala memoria de la nueva mayoría fre...</td>\n",
       "      <td>[9610, 8486, 8448, 7205, 10001, 9999, 9927, 97...</td>\n",
       "      <td>[1, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.13006762, -0.27700594, -0.06630208, -0.186...</td>\n",
       "      <td>[0.2213747, -0.7235562, -0.367401, 0.35953364,...</td>\n",
       "      <td>[-0.34605438, 0.023352358, -0.32479692, 0.4963...</td>\n",
       "      <td>[-0.40992618, -0.3073466, 0.21681017, 1.268957...</td>\n",
       "      <td>[0.06715743, 0.27809557, 0.07517977, 0.5410913...</td>\n",
       "      <td>[0.16733605, 0.26489878, 0.8423751, 0.06611008...</td>\n",
       "      <td>[0.24531865, 0.5975589, -0.4633671, -0.7076185...</td>\n",
       "      <td>[-0.16413306, 0.9792285, -0.8462009, -0.353912...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Japón registró un nuevo déficit comercial réco...   \n",
       "1  UDI acusa \"mala memoria\" de la Nueva Mayoría f...   \n",
       "\n",
       "                                     preprocess_text  \\\n",
       "0  japón registró un nuevo déficit comercial réco...   \n",
       "1  udi acusa mala memoria de la nueva mayoría fre...   \n",
       "\n",
       "                                             encoded        frames conflicto  \\\n",
       "0  [8759, 8914, 9989, 9898, 6584, 8773, 8428, 999...  [0, 1, 0, 0]         0   \n",
       "1  [9610, 8486, 8448, 7205, 10001, 9999, 9927, 97...  [1, 0, 0, 1]         1   \n",
       "\n",
       "  economico humanidad moral  \\\n",
       "0         1         0     0   \n",
       "1         0         0     1   \n",
       "\n",
       "                                            fasttext  \\\n",
       "0  [-0.10552764, -0.27450845, -0.04605328, -0.244...   \n",
       "1  [-0.13006762, -0.27700594, -0.06630208, -0.186...   \n",
       "\n",
       "                                                elmo  \\\n",
       "0  [0.0596153, -0.49882528, -0.41697934, 0.367517...   \n",
       "1  [0.2213747, -0.7235562, -0.367401, 0.35953364,...   \n",
       "\n",
       "                                 beto_embedding_mean  \\\n",
       "0  [-0.23091996, -0.10888031, -0.41678736, 0.6554...   \n",
       "1  [-0.34605438, 0.023352358, -0.32479692, 0.4963...   \n",
       "\n",
       "                                  beto_embedding_cls  \\\n",
       "0  [0.36867273, -0.11450332, -0.70039237, 1.38560...   \n",
       "1  [-0.40992618, -0.3073466, 0.21681017, 1.268957...   \n",
       "\n",
       "                                             Bi-LSTM  \\\n",
       "0  [0.06928335, 0.43591627, 0.09116903, 0.6328583...   \n",
       "1  [0.06715743, 0.27809557, 0.07517977, 0.5410913...   \n",
       "\n",
       "                               Bi-LSTM_AsymetricLoss  \\\n",
       "0  [0.00010779064, -0.005758822, 0.15181892, 0.00...   \n",
       "1  [0.16733605, 0.26489878, 0.8423751, 0.06611008...   \n",
       "\n",
       "                      Beto-finetunning_cross_entropy  \\\n",
       "0  [0.113271594, -0.13349481, -0.17376488, -0.254...   \n",
       "1  [0.24531865, 0.5975589, -0.4633671, -0.7076185...   \n",
       "\n",
       "                          Beto-finetunning_asymetric  \\\n",
       "0  [-0.2676692, 0.06710381, -0.028014764, -0.1380...   \n",
       "1  [-0.16413306, 0.9792285, -0.8462009, -0.353912...   \n",
       "\n",
       "                                              tf-idf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['original_text', 'preprocess_text', 'encoded', 'frames',\n",
    "           'conflicto', 'economico', 'humanidad', 'moral', \"fasttext\", \"elmo\", \"beto_embedding_mean\",\n",
    "           \"beto_embedding_cls\", 'Bi-LSTM', \"Bi-LSTM_AsymetricLoss\", 'Beto-finetunning_cross_entropy',\n",
    "           \"Beto-finetunning_asymetric\", 'tf-idf']\n",
    "\n",
    "df_train = np.load(f\"datasets/fold_{FOLD}_train.npy\", allow_pickle=True)\n",
    "df_train = pd.DataFrame(df_train, columns=columns)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>encoded</th>\n",
       "      <th>frames</th>\n",
       "      <th>conflicto</th>\n",
       "      <th>economico</th>\n",
       "      <th>humanidad</th>\n",
       "      <th>moral</th>\n",
       "      <th>fasttext</th>\n",
       "      <th>elmo</th>\n",
       "      <th>beto_embedding_mean</th>\n",
       "      <th>beto_embedding_cls</th>\n",
       "      <th>Bi-LSTM</th>\n",
       "      <th>Bi-LSTM_AsymetricLoss</th>\n",
       "      <th>Beto-finetunning_cross_entropy</th>\n",
       "      <th>Beto-finetunning_asymetric</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emotiva historia sobre baterista de jazz gana...</td>\n",
       "      <td>[UNK] historia sobre baterista de [UNK] gana t...</td>\n",
       "      <td>[1, 9746, 9965, 3077, 10001, 1, 7881, 8889, 99...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.17857021, -0.3521735, -0.12289284, -0.1905...</td>\n",
       "      <td>[0.33685637, -0.50221187, -0.4782673, 0.339598...</td>\n",
       "      <td>[-0.25053567, -0.022042425, -0.13752246, 0.278...</td>\n",
       "      <td>[0.17801946, 0.00994021, 0.57248706, 0.7987496...</td>\n",
       "      <td>[0.029036798, 0.23114203, 0.080079846, 0.53790...</td>\n",
       "      <td>[0.02488855, -0.006599463, 0.5742614, 0.051586...</td>\n",
       "      <td>[-0.15388533, -0.2834073, -0.4078992, 0.291033...</td>\n",
       "      <td>[0.16847402, -0.2925244, -0.53301275, -0.12231...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daniela Seguel alcanzó el mejor ranking de su ...</td>\n",
       "      <td>daniela seguel alcanzó el mejor ranking de su ...</td>\n",
       "      <td>[8100, 2774, 8471, 9998, 9872, 7795, 10001, 99...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.1077514, -0.24662022, -0.042856704, -0.235...</td>\n",
       "      <td>[0.011217682, -0.34421003, -0.63198024, 0.1278...</td>\n",
       "      <td>[-0.22911884, -0.10708143, -0.24772839, 0.5958...</td>\n",
       "      <td>[0.3702164, -0.10387488, 0.15107627, 1.2201008...</td>\n",
       "      <td>[0.022602014, 0.325852, 0.07890084, 0.67056113...</td>\n",
       "      <td>[0.011398845, -0.005230801, 0.11592025, -0.005...</td>\n",
       "      <td>[-0.47976056, -0.6112696, 0.5419494, 0.0219888...</td>\n",
       "      <td>[-0.06476429, -0.8697158, -0.1499849, 0.392780...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0   Emotiva historia sobre baterista de jazz gana...   \n",
       "1  Daniela Seguel alcanzó el mejor ranking de su ...   \n",
       "\n",
       "                                     preprocess_text  \\\n",
       "0  [UNK] historia sobre baterista de [UNK] gana t...   \n",
       "1  daniela seguel alcanzó el mejor ranking de su ...   \n",
       "\n",
       "                                             encoded        frames conflicto  \\\n",
       "0  [1, 9746, 9965, 3077, 10001, 1, 7881, 8889, 99...  [0, 0, 0, 0]         0   \n",
       "1  [8100, 2774, 8471, 9998, 9872, 7795, 10001, 99...  [0, 0, 1, 0]         0   \n",
       "\n",
       "  economico humanidad moral  \\\n",
       "0         0         0     0   \n",
       "1         0         1     0   \n",
       "\n",
       "                                            fasttext  \\\n",
       "0  [-0.17857021, -0.3521735, -0.12289284, -0.1905...   \n",
       "1  [-0.1077514, -0.24662022, -0.042856704, -0.235...   \n",
       "\n",
       "                                                elmo  \\\n",
       "0  [0.33685637, -0.50221187, -0.4782673, 0.339598...   \n",
       "1  [0.011217682, -0.34421003, -0.63198024, 0.1278...   \n",
       "\n",
       "                                 beto_embedding_mean  \\\n",
       "0  [-0.25053567, -0.022042425, -0.13752246, 0.278...   \n",
       "1  [-0.22911884, -0.10708143, -0.24772839, 0.5958...   \n",
       "\n",
       "                                  beto_embedding_cls  \\\n",
       "0  [0.17801946, 0.00994021, 0.57248706, 0.7987496...   \n",
       "1  [0.3702164, -0.10387488, 0.15107627, 1.2201008...   \n",
       "\n",
       "                                             Bi-LSTM  \\\n",
       "0  [0.029036798, 0.23114203, 0.080079846, 0.53790...   \n",
       "1  [0.022602014, 0.325852, 0.07890084, 0.67056113...   \n",
       "\n",
       "                               Bi-LSTM_AsymetricLoss  \\\n",
       "0  [0.02488855, -0.006599463, 0.5742614, 0.051586...   \n",
       "1  [0.011398845, -0.005230801, 0.11592025, -0.005...   \n",
       "\n",
       "                      Beto-finetunning_cross_entropy  \\\n",
       "0  [-0.15388533, -0.2834073, -0.4078992, 0.291033...   \n",
       "1  [-0.47976056, -0.6112696, 0.5419494, 0.0219888...   \n",
       "\n",
       "                          Beto-finetunning_asymetric  \\\n",
       "0  [0.16847402, -0.2925244, -0.53301275, -0.12231...   \n",
       "1  [-0.06476429, -0.8697158, -0.1499849, 0.392780...   \n",
       "\n",
       "                                              tf-idf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = np.load(f\"datasets/fold_{FOLD}_test.npy\", allow_pickle=True)\n",
    "df_test = pd.DataFrame(df_test, columns=columns)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
